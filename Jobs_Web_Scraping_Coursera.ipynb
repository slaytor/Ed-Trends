{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T14:38:03.848414Z",
     "start_time": "2018-05-30T14:38:01.024339Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from robobrowser import RoboBrowser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "\n",
    "import datetime\n",
    "today = datetime.date.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T14:38:03.854657Z",
     "start_time": "2018-05-30T14:38:03.850514Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursera\n",
    "### Collect All Course Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = 'https://www.coursera.org/browse/'\n",
    "\n",
    "categories = ['arts-and-humanities', 'business', 'computer-science', 'data-science', 'information-technology', \n",
    "                'life-sciences', 'math-and-logic', 'personal-development', 'physical-science-and-engineering', \n",
    "                'social-sciences', 'language-learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_courses = []\n",
    "\n",
    "for category in categories:\n",
    "    result = 'Something'\n",
    "    while result != None:\n",
    "        try:\n",
    "            page = requests.get(base + category)\n",
    "            soup = BeautifulSoup((page).content, 'html.parser')\n",
    "            result = soup.find('h3')\n",
    "        except: \n",
    "            pass\n",
    "    subjects = [x.get('href').replace('#', '/') for x in soup.findAll(\"a\", {\"class\": \"index-item-link\"})]\n",
    "    \n",
    "    for subject in subjects:\n",
    "\n",
    "        for x in range(1, 13):\n",
    "            url = (base + category + subject + '?page=' + str(x))\n",
    "            result = 'Something'\n",
    "            while result != None:\n",
    "                try:\n",
    "                    page_2 = requests.get(url)\n",
    "                    soup_2 = BeautifulSoup((page_2).content, 'html.parser')\n",
    "                    result = soup_2.find('h3')\n",
    "                except: \n",
    "                    pass\n",
    "            courses = [x.get('href') for x in soup_2.findAll('a', {'class': 'rc-OfferingCard nostyle'})]\n",
    "            #print(subject, len(courses), url)\n",
    "            all_courses.append(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = 'Something'\n",
    "while result != None:\n",
    "    try:\n",
    "        page = requests.get('https://www.coursera.org/browse/personal-development')\n",
    "        soup = BeautifulSoup((page).content, 'html.parser')\n",
    "        result = soup.find('h3')\n",
    "    except: \n",
    "        pass\n",
    "courses = [x.get('href') for x in soup.findAll('a', {'class': 'rc-OfferingCard nostyle'})]\n",
    "all_courses.append(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = 'Something'\n",
    "while result != None:\n",
    "    try:\n",
    "        page = requests.get('https://www.coursera.org/browse/math-and-logic')\n",
    "        soup = BeautifulSoup((page).content, 'html.parser')\n",
    "        result = soup.find('h3')\n",
    "    except: \n",
    "        pass\n",
    "courses = [x.get('href') for x in soup.findAll('a', {'class': 'rc-OfferingCard nostyle'})]\n",
    "all_courses.append(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_courses = list(set([item for sublist in all_courses for item in sublist]))\n",
    "#pd.DataFrame({'course_links': all_courses}).to_csv('data/jobs/coursera/coursra_course_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrape all Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T14:38:23.204510Z",
     "start_time": "2018-05-30T14:38:23.190694Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_courses = pd.read_csv('data/jobs/coursera/coursera_course_links.csv')['course_liks'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T14:38:25.330630Z",
     "start_time": "2018-05-30T14:38:25.315320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2158"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learns = [x for x in all_courses if '/learn/' in x]\n",
    "learn_groups = list(chunks(learns, 50))\n",
    "len(learns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T14:40:17.969895Z",
     "start_time": "2018-05-30T14:40:15.229367Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = requests.get('https://www.coursera.org/learn/songwriting-lyrics')\n",
    "soup = BeautifulSoup((page).content, 'html.parser')\n",
    "result = soup.find(\"div\", {'class': 'XdpApp'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T16:16:19.117012Z",
     "start_time": "2018-05-30T14:49:05.527024Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "for idx, group in enumerate(learn_groups):\n",
    "    \n",
    "    #index = idx + 7\n",
    "    print(str(idx))\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for course in group:\n",
    "    \n",
    "        #print(course)\n",
    "        url = ('https://www.coursera.org' + course)\n",
    "\n",
    "        result = 'Something'\n",
    "        tries = 0\n",
    "        while result != None and tries < 5:\n",
    "            try:\n",
    "                page = requests.get(url)\n",
    "                soup = BeautifulSoup((page).content, 'html.parser')\n",
    "                result = soup.find(\"div\", {'class': 'XdpApp'})\n",
    "                tries += 1\n",
    "            except: \n",
    "                pass\n",
    "\n",
    "        if soup.findAll('h1')[-1]:\n",
    "            titles = soup.findAll('h1')[-1].text\n",
    "        else:\n",
    "            titles = ''\n",
    "        if soup.find('p', {'class': 'body-1-text course-description'}):\n",
    "            description = soup.find('p', {'class': 'body-1-text course-description'}).text\n",
    "        else:\n",
    "            description = ''\n",
    "        if soup.find(\"div\", {\"class\": \"ratings-text headline-2-text\"}):\n",
    "            ratings = soup.find(\"div\", {\"class\": \"ratings-text headline-2-text\"}).text\n",
    "        else:\n",
    "            ratings = ''\n",
    "        if soup.find(\"button\", {'class': \"cdp-view-all-button\"}):\n",
    "            reviews = soup.find(\"button\", {'class': \"cdp-view-all-button\"}).text\n",
    "        else:\n",
    "            reviews = ''\n",
    "        if soup.find(\"div\", {\"class\": \"headline-1-text creator-names\"}):\n",
    "            institutions = soup.find(\"div\", {\"class\": \"headline-1-text creator-names\"}).text\n",
    "        else:\n",
    "            institutions = ''\n",
    "        if soup.findAll(\"p\", {\"class\": \"instructor-name\"}):\n",
    "            instructors = [x.text for x in soup.findAll(\"p\", {\"class\": \"instructor-name\"})]\n",
    "        else:\n",
    "            instructors = ''\n",
    "        if soup.find('div', {'class': 'rc-BannerBreadcrumbs caption-text'}):\n",
    "            subjects = [x.find('a').text for x in soup.find('div', {'class': 'rc-BannerBreadcrumbs caption-text'})]\n",
    "        else:\n",
    "            subjects = ''\n",
    "            \n",
    "\n",
    "        i = [x.text for x in soup.findAll(\"span\", {\"class\": \"td-title\"})]\n",
    "        j = [x.text for x in soup.findAll(\"td\", {\"class\": \"td-data\"})]\n",
    "        box_cols = pd.DataFrame([j], columns=i)\n",
    "        \n",
    "        \n",
    "        coursera_df = pd.DataFrame({'title': titles,\n",
    "                       'description': description,\n",
    "                       'ratings': ratings,\n",
    "                       'reviews': reviews,\n",
    "                       'institutions': institutions,\n",
    "                       'instructors': [instructors],\n",
    "                       'subjects': [subjects]})\n",
    "    \n",
    "        coursera_df = pd.concat([coursera_df, box_cols], axis=1)\n",
    "        coursera_df['scrape_date'] = today\n",
    "        coursera_df['url'] = url\n",
    "    \n",
    "        df_list.append(coursera_df)\n",
    "        \n",
    "    pd.concat(df_list).to_csv('data/jobs/coursera/coursera_data/' + str(idx) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T16:23:49.839094Z",
     "start_time": "2018-05-30T16:23:49.281585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>ratings</th>\n",
       "      <th>rated</th>\n",
       "      <th>reviews</th>\n",
       "      <th>description</th>\n",
       "      <th>subjects</th>\n",
       "      <th>institutions</th>\n",
       "      <th>instructors</th>\n",
       "      <th>Basic Info</th>\n",
       "      <th>Commitment</th>\n",
       "      <th>Hardware Req</th>\n",
       "      <th>Language</th>\n",
       "      <th>Level</th>\n",
       "      <th>scrape_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>https://www.coursera.org/learn/machine-learning</td>\n",
       "      <td>74001.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>18573.0</td>\n",
       "      <td>Machine learning is the science of getting com...</td>\n",
       "      <td>['Home', 'Data Science', 'Machine Learning']</td>\n",
       "      <td>Created by:  Stanford University</td>\n",
       "      <td>['Taught by:\\xa0\\xa0Andrew Ng, Co-founder, Cou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English, Subtitles: Spanish, Hindi, Japanese, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>Programming for Everybody (Getting Started wit...</td>\n",
       "      <td>https://www.coursera.org/learn/python</td>\n",
       "      <td>37451.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>10118.0</td>\n",
       "      <td>This course aims to teach everyone the basics ...</td>\n",
       "      <td>['Home', 'Computer Science', 'Software Develop...</td>\n",
       "      <td>Created by:  University of Michigan</td>\n",
       "      <td>['Taught by:\\xa0\\xa0Charles Severance, Associa...</td>\n",
       "      <td>Course 1 of 5 in the Python for Everybody Spec...</td>\n",
       "      <td>2-4 hours/week</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English, Subtitles: German, Chinese (Simplified)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "1514                                   Machine Learning   \n",
       "779   Programming for Everybody (Getting Started wit...   \n",
       "\n",
       "                                                  url  ratings  rated  \\\n",
       "1514  https://www.coursera.org/learn/machine-learning  74001.0    4.9   \n",
       "779             https://www.coursera.org/learn/python  37451.0    4.8   \n",
       "\n",
       "      reviews                                        description  \\\n",
       "1514  18573.0  Machine learning is the science of getting com...   \n",
       "779   10118.0  This course aims to teach everyone the basics ...   \n",
       "\n",
       "                                               subjects  \\\n",
       "1514       ['Home', 'Data Science', 'Machine Learning']   \n",
       "779   ['Home', 'Computer Science', 'Software Develop...   \n",
       "\n",
       "                             institutions  \\\n",
       "1514     Created by:  Stanford University   \n",
       "779   Created by:  University of Michigan   \n",
       "\n",
       "                                            instructors  \\\n",
       "1514  ['Taught by:\\xa0\\xa0Andrew Ng, Co-founder, Cou...   \n",
       "779   ['Taught by:\\xa0\\xa0Charles Severance, Associa...   \n",
       "\n",
       "                                             Basic Info      Commitment  \\\n",
       "1514                                                NaN             NaN   \n",
       "779   Course 1 of 5 in the Python for Everybody Spec...  2-4 hours/week   \n",
       "\n",
       "     Hardware Req                                           Language Level  \\\n",
       "1514          NaN  English, Subtitles: Spanish, Hindi, Japanese, ...   NaN   \n",
       "779           NaN   English, Subtitles: German, Chinese (Simplified)   NaN   \n",
       "\n",
       "     scrape_date  \n",
       "1514  2018-05-30  \n",
       "779   2018-05-30  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "files = [pd.read_csv(file) for file in glob.glob(\"data/jobs/coursera/coursera_data/*.csv\")]\n",
    "coursera = pd.concat(files)\n",
    "coursera.reset_index(inplace=True, drop=True)\n",
    "\n",
    "coursera['description'] = coursera['description'].str.replace('About this course: ', '')\n",
    "coursera['reviews'] = pd.to_numeric(coursera['reviews'].str.lstrip('See all ').str.rstrip(' reviews').str.replace(',', ''))\n",
    "coursera['rated'] = coursera['ratings'].str.split(' out of 5 of ', expand=True)[0]\n",
    "coursera['ratings'] = coursera['ratings'].str.split(' out of 5 of ', expand=True)[1]\n",
    "coursera['rated'] = pd.to_numeric(coursera['rated'].str.lstrip('Rated '))\n",
    "coursera['ratings'] = pd.to_numeric(coursera['ratings'].str.rstrip(' ratings').str.replace(',', ''))\n",
    "\n",
    "coursera = coursera.sort_values('ratings', ascending=False)\n",
    "\n",
    "coursera = coursera[['title', 'url', 'ratings', 'rated', 'reviews', 'description', 'subjects', 'institutions', 'instructors', \n",
    "                     'Basic Info', 'Commitment', 'Hardware Req', 'Language', 'Level', 'scrape_date']]\n",
    "\n",
    "#coursera.to_csv('data/jobs/coursera/coursera_2.csv', index=False)\n",
    "\n",
    "coursera.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trending Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pulling data from site\n",
    "page = requests.get(\"https://www.coursera.org/featured/trending_courses_locale_en_os_web\")\n",
    "\n",
    "# soup thing\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# thing thing\n",
    "links = [x.get('href') for x in list(soup.findAll('a'))]\n",
    "links = [x for x in links if '/learn/' in x]\n",
    "\n",
    "names = []\n",
    "overviews = []\n",
    "ratings = []\n",
    "courses = [x.split('/')[-1] for x in links]\n",
    "\n",
    "for link in links:\n",
    "    page = requests.get(\"https://www.coursera.org/\" + link)\n",
    "    soup = BeautifulSoup((page).content, 'html.parser')\n",
    "    \n",
    "    name = [x.text for x in soup.findAll(\"div\", {\"class\": \"module-name\"})]\n",
    "    names.append(name)\n",
    "    \n",
    "    overview = [x.text for x in soup.findAll(\"p\", {\"class\": \"body-1-text course-description\"})]\n",
    "    overviews.append(overview)\n",
    "    \n",
    "    rating = [x.text for x in soup.findAll(\"div\", {\"class\": \"ratings-text headline-2-text\"})]\n",
    "    ratings.append(rating)\n",
    "    \n",
    "coursera_df = pd.DataFrame({'course': courses,\n",
    "                       'name': names,\n",
    "                       'overview': overviews,\n",
    "                       'rating': ratings})\n",
    "\n",
    "coursera_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
